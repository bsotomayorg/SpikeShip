{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of SpikeShip with neural data\n",
    "\n",
    "A short example using [AllenSDK](https://alleninstitute.github.io/AllenSDK/install.html) and SpikeShip dissimilarity measure to find temporal spiking patterns in NWB datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use NWB dataset as an example of using the SpikeShip algorithm. The first step consists in build another dataset with epochs (i.e, trial, time window) and spike times. This new structure follows the work called \"SPOTDis\" (Grossberger L., et al.) .\n",
    "\n",
    "It consists of two data-structures:\n",
    "\n",
    "1) The spike times vector (e.g. `spike_times = [0.2, 0.6, 0.65, 0.9, 1.1, 0.3, 0.9, 0.2]`) of type float with one entry for each spike.\n",
    "\n",
    "2) The index matrix with the dimensions (#epochs, #neurons, 2) of type int where the last dimension contains a start and a stop index for the spike times vector, indicating which spikes belong to the selected epoch and neuron.\n",
    "\n",
    "ii_spike_times = [\n",
    "\n",
    "    # Epoch 1    \n",
    "    [\n",
    "        # Neuron 1 -> spike(s) at time(s) 0.2, 0.6\n",
    "        [0, 2],\n",
    "        # Neuron 2 -> spike(s) at time(s) 0.65\n",
    "        [2, 3],\n",
    "        # Neuron 3 -> spike(s) at time(s) 0.9, 1.1\n",
    "        [3, 5],\n",
    "    ],\n",
    "    \n",
    "    # Epoch 2\n",
    "    [\n",
    "        # Neuron 1 -> spike(s) at time(s) 0.3\n",
    "        [5, 6],\n",
    "        # Neuron 2 -> spike(s) at time(s) 0.9\n",
    "        [6, 7],\n",
    "        # Neuron 3 -> spike(s) at time(s) 0.2\n",
    "        [8, 9],\n",
    "    ],\n",
    "]\n",
    "\n",
    "The spike times for a given epoch `e` and neuron `n` can be retrieved from the spike times vector using the index matrix as follows:\n",
    "```epoch_neuron_spike_times = spike_times[ii_spike_times[e, n, 0]:ii_spike_times[e, n, 1]]\n",
    "```\n",
    "\n",
    "Check [SPOTDis Demo](https://github.com/LGro/spot/blob/master/notebooks/SPOTDisClust_Demo.ipynb) for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# warnings from jupyter notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# distance computation\n",
    "from spikeship import spikeship\n",
    "\n",
    "# visualization\n",
    "import hdbscan\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = np.load('../example_data/allen_nwb/spike_times.npy')\n",
    "ii_spike_times = np.load('../example_data/allen_nwb/ii_spike_times.npy')\n",
    "stim_labels = np.load('../example_data/allen_nwb/stim_label.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SpikeShip\n",
    "### Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# computation of neuron specific-flows\n",
    "dissimilarity = spikeship.distances(spike_times, ii_spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_model = TSNE(metric='precomputed', n_components=2)\n",
    "embedding_dis  = tsne_model.fit_transform(dissimilarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dissimilarity matrx of neuron-specific shifts and 2D t-SNE embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_values = np.unique(stim_labels)\n",
    "stim_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fs = 13\n",
    "alpha = 0.5\n",
    "marker = 'o'\n",
    "tPlot, axes = plt.subplots(\n",
    "    figsize = (10,4),\n",
    "    nrows=1, ncols=2, sharex=False, sharey=False, \n",
    "    constrained_layout=True\n",
    "    )\n",
    "\n",
    "# Dissimilarity matrix (vis)\n",
    "axes[0].set_title('Dissimilarity matrix', fontsize=fs)\n",
    "np.fill_diagonal(dissimilarity, np.nan) # for visualization purposes\n",
    "im0 = axes[0].imshow(dissimilarity, cmap='PuBu')\n",
    "axes[0].set_xlabel('Epoch', fontsize=fs)\n",
    "axes[0].set_ylabel('Epoch', fontsize=fs);\n",
    "plt.colorbar(im0, ax=axes[0], label='Neuron-specific flows')\n",
    "\n",
    "# 2D tsne embedding (vis)\n",
    "l_colors = ['royalblue', 'orange', 'green', 'purple']\n",
    "for i in range(len(stim_values)):\n",
    "    stim_val = stim_values[i]\n",
    "    mask = (stim_labels == stim_val)\n",
    "    axes[1].set_title('2D t-SNE Embedding', fontsize=fs)\n",
    "    axes[1].scatter(embedding_dis[mask, 0], embedding_dis[mask, 1], s=50, label=stim_val)#, c=np.repeat(l_colors[i], np.sum(mask)), alpha=alpha, marker=marker, facecolors='none')\n",
    "    axes[1].set_xlabel(\"1st Component\", fontsize=fs); axes[1].set_ylabel(\"2nd Component\", fontsize=fs)\n",
    "\n",
    "axes[1].legend(bbox_to_anchor=(1,1), frameon=False, title=\"Drifting gratings\\n(degrees)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with SPOTDis\n",
    "In order to test the SPOTDis module, follow the instructions in the github repository of its authors: https://github.com/LGro/spot/blob/master/notebooks/SPOTDisClust_Demo.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot import spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diss_spot = spot.distances(spike_times, ii_spike_times, metric='SPOTD_xcorr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tSNE Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_model = TSNE(metric='precomputed', n_components=2)\n",
    "embedding_dis  = tsne_model.fit_transform(diss_spot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fs = 13\n",
    "alpha = 0.5\n",
    "marker = 'o'\n",
    "tPlot, axes = plt.subplots(\n",
    "    figsize = (10,4),\n",
    "    nrows=1, ncols=2, sharex=False, sharey=False, \n",
    "    constrained_layout=True\n",
    "    )\n",
    "\n",
    "# Dissimilarity matrix (vis)\n",
    "axes[0].set_title('Dissimilarity matrix', fontsize=fs)\n",
    "np.fill_diagonal(diss_spot, np.nan) # for visualization purposes\n",
    "im0 = axes[0].imshow(diss_spot, cmap='PuBu')\n",
    "axes[0].set_xlabel('Epoch', fontsize=fs)\n",
    "axes[0].set_ylabel('Epoch', fontsize=fs);\n",
    "plt.colorbar(im0, ax=axes[0], label='SPOT distance')\n",
    "\n",
    "# 2D tsne embedding (vis)\n",
    "l_colors = ['royalblue', 'orange', 'green', 'purple']\n",
    "for i in range(len(stim_values)):\n",
    "    stim_val = stim_values[i]\n",
    "    mask = (stim_labels == stim_val)\n",
    "    axes[1].set_title('2D t-SNE Embedding', fontsize=fs)\n",
    "    axes[1].scatter(embedding_dis[mask, 0], embedding_dis[mask, 1], s=50, label=stim_val)#, c=np.repeat(l_colors[i], np.sum(mask)), alpha=alpha, marker=marker, facecolors='none')\n",
    "    axes[1].set_xlabel(\"1st Component\", fontsize=fs); axes[1].set_ylabel(\"2nd Component\", fontsize=fs)\n",
    "\n",
    "axes[1].legend(bbox_to_anchor=(1,1), frameon=False, title=\"Drifting gratings\\n(degrees)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "alpha = 0.5\n",
    "marker = 'o'\n",
    "tPlot, axes = plt.subplots(\n",
    "    figsize = (10,10),\n",
    "    nrows=2, ncols=2, sharex=False, sharey=False, \n",
    "    constrained_layout=True\n",
    "    )\n",
    "# dissimilarity matrix (vis)\n",
    "im0 = axes[0][0].imshow(dissimilarity, cmap='PuBu')\n",
    "axes[0][0].set_xlabel('Epoch')\n",
    "axes[0][0].set_ylabel('Epoch');\n",
    "plt.colorbar(im0, ax=axes[0][0])\n",
    "\n",
    "# 2D tsne embedding (vis)\n",
    "axes[1][0].set_title('2D t-SNE Embedding')\n",
    "axes[1][0].scatter(embedding_dis[:, 0], embedding_dis[:, 1], cmap='Set1_r', s=50,c=cluster_labels_dis, alpha=alpha, marker=marker, facecolors='none')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compute the dissimilarity between two pairs of epochs, SPOTDis has a computational complexity of $\\mathcal{O}(N^2n^2)$, where $N$ is the number of active Neurons, and $n$ the average spikes per epoch. In contrast, SpikeShip has a computational complexity of $\\mathcal{O}(Nn)$ (Quadratic speed-up)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data from Allen Brain Institute (NWB format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a session as example of NWB data from brain-map API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget http://api.brain-map.org//api/v2/well_known_file_download/1026124216"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeship import data_formatter\n",
    "from allensdk.brain_observatory.ecephys.ecephys_session import EcephysSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a NWB session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the session downloaded previouly\n",
    "session = EcephysSession.from_nwb_path('1026124216')\n",
    "\n",
    "# Get the spike_times (dict) from the nwb session\n",
    "nwb_ds = np.array(session.spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create two vectors: a vector of neuron ids `v_neuron_ids`, and a vector for the spike times `v_spike_times`. Neurons ids have to be renamed as integer values from $0$ to $N-1$, with $N$ the number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting spike times and neuron ids as two separated vectors from NWB dataset\n",
    "print (\"Getting spike times and neuron ids as two separated vectors from NWB dataset\")\n",
    "v_neuron_ids  = [] # vect of neurons\n",
    "v_spike_times = [] # vect of spike times\n",
    "c = 0\n",
    "d_neuron_rename = {}\n",
    "for neuron_id, spks in nwb_ds.item().items():\n",
    "    # renaming neuron_ids\n",
    "    for ii in range(len(nwb_ds.item().keys())):\n",
    "        if not neuron_id in d_neuron_rename:\n",
    "            d_neuron_rename[neuron_id] = c\n",
    "            c += 1\n",
    "    # compute each spike time for neuron\n",
    "    for val in spks:\n",
    "        v_neuron_ids.append( int(neuron_id) )\n",
    "        v_spike_times.append( float(val) )\n",
    "\n",
    "v_neuron_ids  = np.array([ d_neuron_rename[neuron] for neuron in v_neuron_ids ] )\n",
    "v_spike_times = np.array(v_spike_times)\n",
    "\n",
    "print ('v_neuron_ids ', v_neuron_ids)\n",
    "print ('v_spike_times', v_spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Formatting\n",
    "Definition of number of `epochs` and time window length (i.e., `time_slide_length`).\n",
    "\n",
    "In this step, we define the local analysis. In this example, we select for the first 1000 seconds of analysis (See variables `ds_min_t` and `ds_max_t`).\n",
    "\n",
    "Each epoch (i.e., temporal window or trial) has a length of `time_slide_length = 5` seconds.\n",
    "We use the method called `data_formatter.allocate_spikes` to convert the data into the SPOTDis and SpikeShip data format. This method returns a new dataset with intermediate epochs that contains an overlap between the previous and posterior epoch. For instance, in this scenario the first epoch considers the time from $0.0$ to $3.0$s and the third epoch goes from $3.0$ to $6.0$s. Thus, the second epoch is defined from $1.5$ to $4.5$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local analysis.\n",
    "ds_min_t = 3               # start point for time window\n",
    "ds_max_t = 1000 + ds_min_t # end point for time window\n",
    "time_slide_length = 5      # time window length (5 secs)\n",
    "\n",
    "# definition of parameters for 'allocate_spikes' method\n",
    "# number of chunks (epochs)\n",
    "n_max_chunks = int(np.ceil( (2*(ds_max_t - ds_min_t)) / time_slide_length ) - 1) # total number of chunks or epochs\n",
    "chunk_increment = time_slide_length / 2. # overlapping\n",
    "total_spikes  = len(v_spike_times)\n",
    "total_neurons = len([item for item in nwb_ds.item()])\n",
    "\n",
    "print ('total_neurons', total_neurons)\n",
    "print ('total_spikes', total_spikes)\n",
    "print ('v_spike_times min:', np.min(v_spike_times))\n",
    "print ('v_spike_times max:', np.max(v_spike_times))\n",
    "print ('ds_min_t selected:', ds_min_t)\n",
    "print ('ds_max_t selected:', ds_max_t)\n",
    "print ('# epochs', n_max_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_spike_times, spike_times = data_formatter.allocate_spikes(\n",
    "    v_spike_times, total_spikes,v_neuron_ids, n_max_chunks, chunk_increment,ds_min_t,total_neurons, time_slide_length\n",
    ")\n",
    "print('[INFO] total spike_times',len(spike_times), 'total epochs', ii_spike_times.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.set_title('Example pattern epoch raster plot')\n",
    "\n",
    "i_epoch = 0 # selected epoch for plotting\n",
    "n_neurons = 100\n",
    "\n",
    "for i_neuron in range(n_neurons):\n",
    "    tmp_epoch_neuron_spike_times = spike_times[\n",
    "        ii_spike_times[i_epoch, i_neuron, 0]:ii_spike_times[i_epoch, i_neuron, 1]]\n",
    "    ax.scatter(tmp_epoch_neuron_spike_times, np.ones(len(tmp_epoch_neuron_spike_times))+i_neuron,\n",
    "               marker='|', c='black')\n",
    "\n",
    "ax.set_yticks(np.arange(0, n_neurons+1, 5))\n",
    "ax.set_ylabel('# Neuron')\n",
    "ax.set_xlabel('Time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Check out our paper for more details:\n",
    "\n",
    "Sotomayor-Gómez, B., Battaglia, F. P., & Vinck, M. (2021). [SpikeShip: A method for fast, unsupervised discovery of high-dimensional neural spiking patterns](https://doi.org/10.1101/2020.06.03.131573). *bioRxiv*.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spikeship_pub]",
   "language": "python",
   "name": "conda-env-spikeship_pub-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
